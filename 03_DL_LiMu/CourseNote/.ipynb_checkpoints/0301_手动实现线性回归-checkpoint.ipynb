{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d9a4d8-c85e-4db4-b206-738e8c8dfa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3508da-ff07-47f2-8c24-f1724fcb6902",
   "metadata": {},
   "source": [
    "首先要实现人工数据集，写一个生成数据集的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b9cdbd-495c-44f2-80d0-03680acf8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_data(w, b, num):\n",
    "    '''\n",
    "    params:\n",
    "        w: 权重\n",
    "        b: 偏置\n",
    "        num: 数据量\n",
    "    return:\n",
    "        X: 输入\n",
    "        y: 输出\n",
    "    '''\n",
    "    X = torch.normal(0, 1, (num, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape(num, -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f396fc-1f82-42f4-8001-631b2566cd78",
   "metadata": {},
   "source": [
    "测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb898d00-e2b4-42b2-b59f-ca76bf63b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2]), torch.Size([10, 1]), 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor([2, 1.0])\n",
    "b = float(3.0)\n",
    "X, y = synthetic_data(w, b, 10)\n",
    "X.shape, y.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b4919-be0d-4fde-a7d2-9cb33ab8979b",
   "metadata": {},
   "source": [
    "然后构造损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8d91fc-195e-4206-a038-3639ef057366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, y_hat):\n",
    "    '''\n",
    "    params:\n",
    "        y: 标签\n",
    "        y_hat: 拟合值\n",
    "    return:\n",
    "        loss: 平方损失\n",
    "    '''\n",
    "    return torch.matmul((y-y_hat).T, y-y_hat) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b66394-139b-4f18-bf0c-636981a321ac",
   "metadata": {},
   "source": [
    "构造线性回归（拟合）模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e92833c-eb26-4313-b57a-6265c39facf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(w, x, b):\n",
    "    '''\n",
    "    params:\n",
    "        w: 权重\n",
    "        x: 输入\n",
    "        b: 偏置\n",
    "    return:\n",
    "        y: 输出\n",
    "    '''\n",
    "    return torch.matmul(x, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3822031-fb71-4f45-b875-154a9a1fc3af",
   "metadata": {},
   "source": [
    "实现梯度下降算法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fecdb62c-2fa1-4cf7-ac3a-5a038e8194d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr):\n",
    "    '''\n",
    "    params:\n",
    "        params: 拟合的参数\n",
    "        lr: 学习率\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163510b7-2e44-4261-8c8e-913211f20886",
   "metadata": {},
   "source": [
    "数据随机读取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc165347-b697-42de-b254-2a0c0302d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size,features,labels):\n",
    "    '''\n",
    "    params:\n",
    "        batch_size: 批量\n",
    "        features: 输入\n",
    "        labels: 标准输出\n",
    "    return:\n",
    "        batch_features: 批量输入\n",
    "        batch_labels: 批量输出\n",
    "    '''\n",
    "    num_examples = len(features)  # 样本个数\n",
    "    indices = list(range(num_examples)) # 样本索引\n",
    "    # 这些样本是随即读取的，没有特定的顺序\n",
    "    random.shuffle(indices) # 把索引随即打乱\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(indices[i:min(i+batch_size,num_examples)]) # 当i+batch_size超出时，取num_examples    \n",
    "        yield features[batch_indices], labels[batch_indices] # 获得随即顺序的特征，及对应的标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07431c2a-d3a3-4154-9e47-f0f9b46cc6ea",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "331636ac-282f-4419-876c-aeacc17617fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1,loss: 0.000118...\n",
      "epoch: 2,loss: 0.000119...\n",
      "epoch: 3,loss: 0.000106...\n",
      "epoch: 4,loss: 0.000106...\n",
      "epoch: 5,loss: 0.000103...\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 5\n",
    "batch_size = 10\n",
    "lr = 0.2\n",
    "w_real = torch.tensor([2.0, 1.0])\n",
    "b_real = 3.0\n",
    "num = 1000\n",
    "features, labels = synthetic_data(w_real, b_real, num)\n",
    "\n",
    "w = torch.normal(0, 1, (2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "for epoch in range(epoch_num):\n",
    "    for X,y in data_iter(batch_size,features,labels):\n",
    "        l = loss_fn(linear_model(w, X, b),y) # x和y的小批量损失\n",
    "        # 因为l是形状是(batch_size,1)，而不是一个标量。l中所有元素被加到一起\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.backward()\n",
    "        sgd([w,b],lr) #使用参数的梯度更新参数\n",
    "    with torch.no_grad():\n",
    "        train_l = loss_fn(linear_model(w, features, b), labels)\n",
    "        print(f'epoch: {epoch+1},loss: {float(train_l):f}...') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617259a0-d474-4db3-8ab5-8da03264740f",
   "metadata": {},
   "source": [
    "完毕"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45296aa8-a4bc-4089-aa04-3ad3fac58ba9",
   "metadata": {},
   "source": [
    "补充：python的List是不能进行 List[[1,3,5]] 的操作的，但是似乎 tensor 张量可以，进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b820433-7483-4437-b7b8-e77fb761c867",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m a[[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m]]\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "a = [0,1,2,3,4,5]\n",
    "a[[1,3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b379be8-e6b5-4dcd-94af-02b0c5d783cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([0,1,2,3,4,5])\n",
    "b[[1,3,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2eb38-4db1-4c8e-b4d2-8b12d9890cf7",
   "metadata": {},
   "source": [
    "总结：牛的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144844d-0092-48ae-bf39-f5cabfc3271f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch221",
   "language": "python",
   "name": "pytorch221"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
